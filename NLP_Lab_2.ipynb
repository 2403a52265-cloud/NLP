{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvEgpLy5zBfSQSJHbcVlUy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52265-cloud/NLP/blob/main/NLP_Lab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WaVyoMYhXybG"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Hospital = \"A medical corpus is a large collection of medical and healthcare-related texts. It includes clinical notes, discharge summaries, and medical journals for research. The Hippocratic Corpus is the earliest example of ancient medical writings. Modern corpora train NLP/AI models for medical data analysis and diagnostics. The English Medical Corpus contains 33 million words collected from the web\""
      ],
      "metadata": {
        "id": "RMwMm8rjYSVz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(Hospital)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIZBCfp7ZNCi",
        "outputId": "4f015b1e-ee78-4b8f-8867-162742346362"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'medical',\n",
              " 'corpus',\n",
              " 'is',\n",
              " 'a',\n",
              " 'large',\n",
              " 'collection',\n",
              " 'of',\n",
              " 'medical',\n",
              " 'and',\n",
              " 'healthcare-related',\n",
              " 'texts',\n",
              " '.',\n",
              " 'It',\n",
              " 'includes',\n",
              " 'clinical',\n",
              " 'notes',\n",
              " ',',\n",
              " 'discharge',\n",
              " 'summaries',\n",
              " ',',\n",
              " 'and',\n",
              " 'medical',\n",
              " 'journals',\n",
              " 'for',\n",
              " 'research',\n",
              " '.',\n",
              " 'The',\n",
              " 'Hippocratic',\n",
              " 'Corpus',\n",
              " 'is',\n",
              " 'the',\n",
              " 'earliest',\n",
              " 'example',\n",
              " 'of',\n",
              " 'ancient',\n",
              " 'medical',\n",
              " 'writings',\n",
              " '.',\n",
              " 'Modern',\n",
              " 'corpora',\n",
              " 'train',\n",
              " 'NLP/AI',\n",
              " 'models',\n",
              " 'for',\n",
              " 'medical',\n",
              " 'data',\n",
              " 'analysis',\n",
              " 'and',\n",
              " 'diagnostics',\n",
              " '.',\n",
              " 'The',\n",
              " 'English',\n",
              " 'Medical',\n",
              " 'Corpus',\n",
              " 'contains',\n",
              " '33',\n",
              " 'million',\n",
              " 'words',\n",
              " 'collected',\n",
              " 'from',\n",
              " 'the',\n",
              " 'web']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(Hospital)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VVNqbkEZ78A",
        "outputId": "5c6ecc5e-ed9b-4929-b30d-0c2d7cf3d82a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A medical corpus is a large collection of medical and healthcare-related texts.',\n",
              " 'It includes clinical notes, discharge summaries, and medical journals for research.',\n",
              " 'The Hippocratic Corpus is the earliest example of ancient medical writings.',\n",
              " 'Modern corpora train NLP/AI models for medical data analysis and diagnostics.',\n",
              " 'The English Medical Corpus contains 33 million words collected from the web']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvfhMtqiaPUc",
        "outputId": "1354a097-2318-4629-ef03-4b6dfd5b1616"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(Hospital)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2FnJANha-XU",
        "outputId": "f0208ea5-7d56-4087-8a4c-4763db0b6f66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'medical',\n",
              " 'corpus',\n",
              " 'is',\n",
              " 'a',\n",
              " 'large',\n",
              " 'collection',\n",
              " 'of',\n",
              " 'medical',\n",
              " 'and',\n",
              " 'healthcare-related',\n",
              " 'texts',\n",
              " '.',\n",
              " 'It',\n",
              " 'includes',\n",
              " 'clinical',\n",
              " 'notes',\n",
              " ',',\n",
              " 'discharge',\n",
              " 'summaries',\n",
              " ',',\n",
              " 'and',\n",
              " 'medical',\n",
              " 'journals',\n",
              " 'for',\n",
              " 'research',\n",
              " '.',\n",
              " 'The',\n",
              " 'Hippocratic',\n",
              " 'Corpus',\n",
              " 'is',\n",
              " 'the',\n",
              " 'earliest',\n",
              " 'example',\n",
              " 'of',\n",
              " 'ancient',\n",
              " 'medical',\n",
              " 'writings',\n",
              " '.',\n",
              " 'Modern',\n",
              " 'corpora',\n",
              " 'train',\n",
              " 'NLP/AI',\n",
              " 'models',\n",
              " 'for',\n",
              " 'medical',\n",
              " 'data',\n",
              " 'analysis',\n",
              " 'and',\n",
              " 'diagnostics',\n",
              " '.',\n",
              " 'The',\n",
              " 'English',\n",
              " 'Medical',\n",
              " 'Corpus',\n",
              " 'contains',\n",
              " '33',\n",
              " 'million',\n",
              " 'words',\n",
              " 'collected',\n",
              " 'from',\n",
              " 'the',\n",
              " 'web']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Hospital = \"A medical corpus is a large collection of medical and healthcare-related texts. It includes clinical notes, discharge summaries, and medical journals for research. The Hippocratic Corpus is the earliest example of ancient medical writings. Modern corpora train NLP/AI models for medical data analysis and diagnostics. The English Medical Corpus contains 33 million words collected from the web\"\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "words_in_quote = word_tokenize(Hospital)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_list =[]\n",
        "for word in words_in_quote:\n",
        "    if word.casefold() not in stop_words:\n",
        "        filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAgKOsSibJAz",
        "outputId": "54b5dfc8-dfd8-45fc-f632-a5ce15e23e31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['medical',\n",
              " 'corpus',\n",
              " 'large',\n",
              " 'collection',\n",
              " 'medical',\n",
              " 'healthcare-related',\n",
              " 'texts',\n",
              " '.',\n",
              " 'includes',\n",
              " 'clinical',\n",
              " 'notes',\n",
              " ',',\n",
              " 'discharge',\n",
              " 'summaries',\n",
              " ',',\n",
              " 'medical',\n",
              " 'journals',\n",
              " 'research',\n",
              " '.',\n",
              " 'Hippocratic',\n",
              " 'Corpus',\n",
              " 'earliest',\n",
              " 'example',\n",
              " 'ancient',\n",
              " 'medical',\n",
              " 'writings',\n",
              " '.',\n",
              " 'Modern',\n",
              " 'corpora',\n",
              " 'train',\n",
              " 'NLP/AI',\n",
              " 'models',\n",
              " 'medical',\n",
              " 'data',\n",
              " 'analysis',\n",
              " 'diagnostics',\n",
              " '.',\n",
              " 'English',\n",
              " 'Medical',\n",
              " 'Corpus',\n",
              " 'contains',\n",
              " '33',\n",
              " 'million',\n",
              " 'words',\n",
              " 'collected',\n",
              " 'web']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(Hospital)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52xMjCtacKQc",
        "outputId": "1a690ebc-07a4-4776-9cf0-20c161ec5144"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'medic',\n",
              " 'corpu',\n",
              " 'is',\n",
              " 'a',\n",
              " 'larg',\n",
              " 'collect',\n",
              " 'of',\n",
              " 'medic',\n",
              " 'and',\n",
              " 'healthcare-rel',\n",
              " 'text',\n",
              " '.',\n",
              " 'it',\n",
              " 'includ',\n",
              " 'clinic',\n",
              " 'note',\n",
              " ',',\n",
              " 'discharg',\n",
              " 'summari',\n",
              " ',',\n",
              " 'and',\n",
              " 'medic',\n",
              " 'journal',\n",
              " 'for',\n",
              " 'research',\n",
              " '.',\n",
              " 'the',\n",
              " 'hippocrat',\n",
              " 'corpu',\n",
              " 'is',\n",
              " 'the',\n",
              " 'earliest',\n",
              " 'exampl',\n",
              " 'of',\n",
              " 'ancient',\n",
              " 'medic',\n",
              " 'write',\n",
              " '.',\n",
              " 'modern',\n",
              " 'corpora',\n",
              " 'train',\n",
              " 'nlp/ai',\n",
              " 'model',\n",
              " 'for',\n",
              " 'medic',\n",
              " 'data',\n",
              " 'analysi',\n",
              " 'and',\n",
              " 'diagnost',\n",
              " '.',\n",
              " 'the',\n",
              " 'english',\n",
              " 'medic',\n",
              " 'corpu',\n",
              " 'contain',\n",
              " '33',\n",
              " 'million',\n",
              " 'word',\n",
              " 'collect',\n",
              " 'from',\n",
              " 'the',\n",
              " 'web']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "Hospital = \"A medical corpus is a large collection of medical and healthcare-related texts. It includes clinical notes, discharge summaries, and medical journals for research. The Hippocratic Corpus is the earliest example of ancient medical writings. Modern corpora train NLP/AI models for medical data analysis and diagnostics. The English Medical Corpus contains 33 million words collected from the web\"\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(Hospital)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE4V_M3MdSEF",
        "outputId": "2513b8e5-ac89-4f38-999a-5557b72a5a93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A ---> a\n",
            "medical ---> medic\n",
            "corpus ---> corpus\n",
            "is ---> is\n",
            "a ---> a\n",
            "large ---> larg\n",
            "collection ---> collect\n",
            "of ---> of\n",
            "medical ---> medic\n",
            "and ---> and\n",
            "healthcare-related ---> healthcare-rel\n",
            "texts ---> text\n",
            ". ---> .\n",
            "It ---> it\n",
            "includes ---> includ\n",
            "clinical ---> clinic\n",
            "notes ---> note\n",
            ", ---> ,\n",
            "discharge ---> discharg\n",
            "summaries ---> summari\n",
            ", ---> ,\n",
            "and ---> and\n",
            "medical ---> medic\n",
            "journals ---> journal\n",
            "for ---> for\n",
            "research ---> research\n",
            ". ---> .\n",
            "The ---> the\n",
            "Hippocratic ---> hippocrat\n",
            "Corpus ---> corpus\n",
            "is ---> is\n",
            "the ---> the\n",
            "earliest ---> earliest\n",
            "example ---> exampl\n",
            "of ---> of\n",
            "ancient ---> ancient\n",
            "medical ---> medic\n",
            "writings ---> write\n",
            ". ---> .\n",
            "Modern ---> modern\n",
            "corpora ---> corpora\n",
            "train ---> train\n",
            "NLP/AI ---> nlp/ai\n",
            "models ---> model\n",
            "for ---> for\n",
            "medical ---> medic\n",
            "data ---> data\n",
            "analysis ---> analysi\n",
            "and ---> and\n",
            "diagnostics ---> diagnost\n",
            ". ---> .\n",
            "The ---> the\n",
            "English ---> english\n",
            "Medical ---> medic\n",
            "Corpus ---> corpus\n",
            "contains ---> contain\n",
            "33 ---> 33\n",
            "million ---> million\n",
            "words ---> word\n",
            "collected ---> collect\n",
            "from ---> from\n",
            "the ---> the\n",
            "web ---> web\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(Hospital)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuAqNPOfellL",
        "outputId": "fd913171-df55-4494-867d-085a0e299ca3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A ---> a\n",
            "medical ---> med\n",
            "corpus ---> corp\n",
            "is ---> is\n",
            "a ---> a\n",
            "large ---> larg\n",
            "collection ---> collect\n",
            "of ---> of\n",
            "medical ---> med\n",
            "and ---> and\n",
            "healthcare-related ---> healthcare-related\n",
            "texts ---> text\n",
            ". ---> .\n",
            "It ---> it\n",
            "includes ---> includ\n",
            "clinical ---> clin\n",
            "notes ---> not\n",
            ", ---> ,\n",
            "discharge ---> discharg\n",
            "summaries ---> sum\n",
            ", ---> ,\n",
            "and ---> and\n",
            "medical ---> med\n",
            "journals ---> journ\n",
            "for ---> for\n",
            "research ---> research\n",
            ". ---> .\n",
            "The ---> the\n",
            "Hippocratic ---> hippocr\n",
            "Corpus ---> corp\n",
            "is ---> is\n",
            "the ---> the\n",
            "earliest ---> earliest\n",
            "example ---> exampl\n",
            "of ---> of\n",
            "ancient ---> ant\n",
            "medical ---> med\n",
            "writings ---> writ\n",
            ". ---> .\n",
            "Modern ---> modern\n",
            "corpora ---> corpor\n",
            "train ---> train\n",
            "NLP/AI ---> nlp/ai\n",
            "models ---> model\n",
            "for ---> for\n",
            "medical ---> med\n",
            "data ---> dat\n",
            "analysis ---> analys\n",
            "and ---> and\n",
            "diagnostics ---> diagnost\n",
            ". ---> .\n",
            "The ---> the\n",
            "English ---> engl\n",
            "Medical ---> med\n",
            "Corpus ---> corp\n",
            "contains ---> contain\n",
            "33 ---> 33\n",
            "million ---> mil\n",
            "words ---> word\n",
            "collected ---> collect\n",
            "from ---> from\n",
            "the ---> the\n",
            "web ---> web\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "words = word_tokenize(Hospital)\n",
        "for word in words:\n",
        "    print(word,\"--->\",reg_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9etJR1le5wZ",
        "outputId": "9444d5e1-1f4b-460d-bb64-93dd80cf0a08"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A ---> A\n",
            "medical ---> medical\n",
            "corpus ---> corpu\n",
            "is ---> is\n",
            "a ---> a\n",
            "large ---> larg\n",
            "collection ---> collection\n",
            "of ---> of\n",
            "medical ---> medical\n",
            "and ---> and\n",
            "healthcare-related ---> healthcare-related\n",
            "texts ---> text\n",
            ". ---> .\n",
            "It ---> It\n",
            "includes ---> include\n",
            "clinical ---> clinical\n",
            "notes ---> note\n",
            ", ---> ,\n",
            "discharge ---> discharg\n",
            "summaries ---> summarie\n",
            ", ---> ,\n",
            "and ---> and\n",
            "medical ---> medical\n",
            "journals ---> journal\n",
            "for ---> for\n",
            "research ---> research\n",
            ". ---> .\n",
            "The ---> The\n",
            "Hippocratic ---> Hippocratic\n",
            "Corpus ---> Corpu\n",
            "is ---> is\n",
            "the ---> the\n",
            "earliest ---> earliest\n",
            "example ---> exampl\n",
            "of ---> of\n",
            "ancient ---> ancient\n",
            "medical ---> medical\n",
            "writings ---> writing\n",
            ". ---> .\n",
            "Modern ---> Modern\n",
            "corpora ---> corpora\n",
            "train ---> train\n",
            "NLP/AI ---> NLP/AI\n",
            "models ---> model\n",
            "for ---> for\n",
            "medical ---> medical\n",
            "data ---> data\n",
            "analysis ---> analysi\n",
            "and ---> and\n",
            "diagnostics ---> diagnostic\n",
            ". ---> .\n",
            "The ---> The\n",
            "English ---> English\n",
            "Medical ---> Medical\n",
            "Corpus ---> Corpu\n",
            "contains ---> contain\n",
            "33 ---> 33\n",
            "million ---> million\n",
            "words ---> word\n",
            "collected ---> collected\n",
            "from ---> from\n",
            "the ---> the\n",
            "web ---> web\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Hospital = \"A medical corpus is a large collection of medical and healthcare-related texts. It includes clinical notes, discharge summaries, and medical journals for research. The Hippocratic Corpus is the earliest example of ancient medical writings. Modern corpora train NLP/AI models for medical data analysis and diagnostics. The English Medical Corpus contains 33 million words collected from the web\"\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(Hospital)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkXQbhN1fepG",
        "outputId": "17780577-1906-4c1b-ebf9-c020779ff9d5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A ---> A\n",
            "medical ---> medical\n",
            "corpus ---> corpus\n",
            "is ---> is\n",
            "a ---> a\n",
            "large ---> large\n",
            "collection ---> collection\n",
            "of ---> of\n",
            "medical ---> medical\n",
            "and ---> and\n",
            "healthcare-related ---> healthcare-related\n",
            "texts ---> text\n",
            ". ---> .\n",
            "It ---> It\n",
            "includes ---> includes\n",
            "clinical ---> clinical\n",
            "notes ---> note\n",
            ", ---> ,\n",
            "discharge ---> discharge\n",
            "summaries ---> summary\n",
            ", ---> ,\n",
            "and ---> and\n",
            "medical ---> medical\n",
            "journals ---> journal\n",
            "for ---> for\n",
            "research ---> research\n",
            ". ---> .\n",
            "The ---> The\n",
            "Hippocratic ---> Hippocratic\n",
            "Corpus ---> Corpus\n",
            "is ---> is\n",
            "the ---> the\n",
            "earliest ---> earliest\n",
            "example ---> example\n",
            "of ---> of\n",
            "ancient ---> ancient\n",
            "medical ---> medical\n",
            "writings ---> writing\n",
            ". ---> .\n",
            "Modern ---> Modern\n",
            "corpora ---> corpus\n",
            "train ---> train\n",
            "NLP/AI ---> NLP/AI\n",
            "models ---> model\n",
            "for ---> for\n",
            "medical ---> medical\n",
            "data ---> data\n",
            "analysis ---> analysis\n",
            "and ---> and\n",
            "diagnostics ---> diagnostics\n",
            ". ---> .\n",
            "The ---> The\n",
            "English ---> English\n",
            "Medical ---> Medical\n",
            "Corpus ---> Corpus\n",
            "contains ---> contains\n",
            "33 ---> 33\n",
            "million ---> million\n",
            "words ---> word\n",
            "collected ---> collected\n",
            "from ---> from\n",
            "the ---> the\n",
            "web ---> web\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xcsCe2WcgW0e",
        "outputId": "58e34192-5be9-4951-a51c-88f5526b8a07"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\",pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1bwCvTxrghPY",
        "outputId": "9769a57a-82ac-45c1-c9dc-5627b5501d97"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer,SnowballStemmer,LancasterStemmer, RegexpStemmer, WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer(language='english')\n",
        "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word_list = [\"friend\" , \"friendship\" , \"friends\" , \"friendships\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(\"Word\",\"Porter Stemmer\",\"Snowball Stemmer\",\"Lancaster Stemmer\",\"Regexp Stemmer\",\"Lemmatizer\")) # Fixed missing ')'\n",
        "print(\"-\"*160)\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(word,porter.stem(word),snowball.stem(word),lancaster.stem(word),reg_stemmer.stem(word), # Fixed missing ',' and ')'\n",
        "    lemmatizer.lemmatize(word,pos='v')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4dOvPT1goPs",
        "outputId": "241c7c46-19a5-498e-aa34-74ef81e859c1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          Lemmatizer                                        \n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "friend              friend              friend              friend                        friend                                  friend                                            \n",
            "friendship          friendship          friendship          friend                        friendship                              friendship                                        \n",
            "friends             friend              friend              friend                        friend                                  friends                                           \n",
            "friendships         friendship          friendship          friend                        friendship                              friendships                                       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}